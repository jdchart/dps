{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b66129b",
   "metadata": {},
   "source": [
    "# 4. Window clustering\n",
    "In this notebook we:\n",
    "- Load the stats created in step 2\n",
    "- Create a clustering of the various windows according to mean, std, min, max, word count and bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb4d4c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b71411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "import sys\n",
    "!echo \"Purging pip environment and installing packages...\"\n",
    "!{sys.executable} -m pip cache purge \n",
    "!{sys.executable} -m pip uninstall -y jhutils \n",
    "!{sys.executable} -m pip install -q seaborn\n",
    "!{sys.executable} -m pip install -q git+https://github.com/jdchart/jh-py-utils.git\n",
    "\n",
    "# Imports\n",
    "print(\"Importing packages...\")\n",
    "import os\n",
    "from jhutils.local_files import collect_files\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffad270",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS = \"/Users/jacob/Documents/Repos/dps/projects/data/output/norm-stats\"\n",
    "\n",
    "stat_folders = [f for f in os.listdir(STATS) if os.path.isdir(os.path.join(STATS, f))]\n",
    "stat_folders.remove(\"dps_curve_manual\")\n",
    "print(f\"Sucsessfully found {len(stat_folders)} statistics folders!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ff8b9",
   "metadata": {},
   "source": [
    "## Analysis config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b95137",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9514a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 3\n",
    "\n",
    "window_stats = []\n",
    "files = collect_files(os.path.join(STATS, stat_folders[INDEX]), [\"csv\"])\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    window_stats.append(df)\n",
    "\n",
    "combined_df = pd.concat(window_stats, ignore_index=True)\n",
    "\n",
    "df_windows = pd.DataFrame(combined_df).round(2)\n",
    "\n",
    "features = ['mean', 'std', 'min', 'max', 'count_words'] + [col for col in df_windows.columns if col.startswith(\"perc\")]\n",
    "X = df_windows[features].fillna(0)\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Clustering\n",
    "kmeans = KMeans(n_clusters = NUM_CLUSTERS, random_state = 0)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "df_windows[\"cluster\"] = labels\n",
    "\n",
    "# R√©duction dimensionnelle\n",
    "X_tsne = TSNE(n_components=2, perplexity=10, random_state=0).fit_transform(X_scaled)\n",
    "\n",
    "utils.display_scatter(X_tsne, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fea8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_files = sorted(\n",
    "    collect_files(os.path.join(STATS, stat_folders[INDEX]), [\"csv\"]),\n",
    "    key=lambda f: os.path.basename(f)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, len(ordered_files) * 0.5))\n",
    "\n",
    "for i, file in enumerate(ordered_files):\n",
    "    key_ = f\"{os.path.splitext(os.path.basename(file))[0]}.json\"\n",
    "    file_windows = df_windows[df_windows[\"file\"] == key_]\n",
    "\n",
    "    for _, row in file_windows.iterrows():\n",
    "        color = utils.cluster_colors_hex[int(row[\"cluster\"])]\n",
    "        plt.plot([row[\"start_time_s\"] / 60, row[\"end_time_s\"] / 60],\n",
    "                 [i, i], color=color, linewidth=6)\n",
    "\n",
    "\n",
    "plt.yticks(\n",
    "    range(len(ordered_files)),\n",
    "    [os.path.splitext(os.path.basename(f))[0][:12] for f in ordered_files]\n",
    ")\n",
    "plt.xlabel(\"Time (minutes)\")\n",
    "plt.title(\"Timeline des clusters rythmiques (par fen√™tre)\")\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360e5b8",
   "metadata": {},
   "source": [
    "# Process all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d133610",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DEST = \"/Users/jacob/Documents/Repos/dps/projects/data/output/clusters\"\n",
    "os.makedirs(OUTPUT_DEST, exist_ok = True)\n",
    "\n",
    "for sub_folder in stat_folders:\n",
    "\n",
    "    window_stats = []\n",
    "    files = collect_files(os.path.join(STATS, sub_folder), [\"csv\"])\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, index_col=0)\n",
    "        window_stats.append(df)\n",
    "\n",
    "    combined_df = pd.concat(window_stats, ignore_index=True)\n",
    "\n",
    "    df_windows = pd.DataFrame(combined_df).round(2)\n",
    "\n",
    "    features = ['mean', 'std', 'min', 'max', 'count_words'] + [col for col in df_windows.columns if col.startswith(\"perc\")]\n",
    "    X = df_windows[features].fillna(0)\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Clustering\n",
    "    kmeans = KMeans(n_clusters = NUM_CLUSTERS, random_state = 0)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    df_windows[\"cluster\"] = labels\n",
    "\n",
    "    # R√©duction dimensionnelle\n",
    "    X_tsne = TSNE(n_components=2, perplexity=10, random_state=0).fit_transform(X_scaled)\n",
    "\n",
    "    ordered_files = sorted(\n",
    "        collect_files(os.path.join(STATS, sub_folder), [\"csv\"]),\n",
    "        key=lambda f: os.path.basename(f)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(14, len(ordered_files) * 0.5))\n",
    "\n",
    "    for i, file in enumerate(ordered_files):\n",
    "        key_ = f\"{os.path.splitext(os.path.basename(file))[0]}.json\"\n",
    "        file_windows = df_windows[df_windows[\"file\"] == key_]\n",
    "\n",
    "        for _, row in file_windows.iterrows():\n",
    "            color = utils.cluster_colors_hex[int(row[\"cluster\"])]\n",
    "            plt.plot([row[\"start_time_s\"] / 60, row[\"end_time_s\"] / 60],\n",
    "                    [i, i], color=color, linewidth=6)\n",
    "\n",
    "    plt.yticks(\n",
    "        range(len(ordered_files)),\n",
    "        [os.path.splitext(os.path.basename(f))[0][:12] for f in ordered_files]\n",
    "    )\n",
    "    plt.xlabel(\"Time (minutes)\")\n",
    "    plt.title(\"Timeline des clusters rythmiques (par fen√™tre)\")\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DEST, f\"{sub_folder}.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"üëç Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
